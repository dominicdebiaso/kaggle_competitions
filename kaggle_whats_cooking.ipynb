{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Kaggle: What's Cooking?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import train data and read to df\n",
    "path = '/Users/dominicdebiaso/Development/datasets/'\n",
    "cooking_train_data = path + 'kaggle_cooking_train.json'\n",
    "df = pd.read_json(cooking_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EDA\n",
    "# df.cuisine.unique()\n",
    "# Number of unique ingredients\n",
    "# ingredients_unique = [x for sublist in ingredients for x in sublist]\n",
    "# len(set(ingredients_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize 'CountVectorizer' object (ie. the bag of words tool). To limit\n",
    "# the number of feature vectors, the 2200 most frequent are chosen. Since \n",
    "# the words are represented as a vector, it'll be a sparse matrix.\n",
    "# Further, 'fit' and 'transform' modeling is stored within the vectorizer.\n",
    "vectorizer = CountVectorizer(max_features = 2200)\n",
    "\n",
    "# Extract ingredients and convert them to a single list of strings\n",
    "# Replace commas with a whitespace for each ingredient list\n",
    "ingredients = df['ingredients']\n",
    "ingredients_list = [' '.join(x) for x in ingredients]\n",
    "\n",
    "## Bag of Words representation\n",
    "# Machine learning on text documents requires text content be converted\n",
    "# into numerical feature vectors. An integer id is assigned to each word\n",
    "# occuring in the document. For each document, count the number of times\n",
    "# the word occurs (i) and store it next to it's integer value (j); x[i, j].\n",
    "\n",
    "# Fit estimator and learn vocab list\n",
    "# Then transform training data into feature vectors\n",
    "# Input should be a list of strings\n",
    "\n",
    "# Fit and then transform, make it possible to fit on training data and \n",
    "# transform on test data. So transformation on training and testing \n",
    "# dataset are identical, and the tranformed data can be compared and \n",
    "# computed together.\n",
    "\n",
    "# Using fit_transform on two datasets would result in two different\n",
    "# coordinate systems for the transformed data. So the transformed result \n",
    "# cannot be computer or computed together.\n",
    "\n",
    "# Fits the training data\n",
    "# vectorizer.fit(ingredients_list)\n",
    "bag_of_words = vectorizer.fit(ingredients_list)\n",
    "\n",
    "# Transform words into vector representation\n",
    "# e.g. (document id, word id) -- word frequency\n",
    "# Then convert to numpy arrays from scipy sparse matrix\n",
    "# The array contains 0s for words not found in that particular document\n",
    "bag_of_words_asArray = vectorizer.transform(ingredients_list).toarray()\n",
    "\n",
    "# View shape\n",
    "# print(bag_of_words_asArray.shape)\n",
    "\n",
    "# Vectors of a given document id\n",
    "# print(bag_of_words_asArray[1999])\n",
    "\n",
    "# Vector of a given ingredient\n",
    "# vectorizer.vocabulary_.get(u'parsley')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import test data\n",
    "cooking_test_data = path + 'kaggle_cooking_test.json'\n",
    "df_test = pd.read_json(cooking_test_data)\n",
    "\n",
    "# Perform similar ingredient transformation\n",
    "ingredients_test = df_test['ingredients']\n",
    "ingredients_list_test = [' '.join(x) for x in ingredients_test]\n",
    "ingredients_asArray_test = vectorizer.transform(ingredients_list_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Supervised Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Random Forest fits a number of decision trees on various sub-samples of\n",
    "# dataset and use averaging to improve predictive accuracy and control\n",
    "# over-fitting. A form of ensemble learning that relies on an ensemble\n",
    "# of decision trees.\n",
    "\n",
    "# Initialize random forest classifier with 800 trees and fit with bag of words\n",
    "# Only the hyperparameter 'n_estimators' was used\n",
    "# random_forest = RandomForestClassifier(n_estimators = 800)\n",
    "# random_forest = random_forest.fit(bag_of_words_asArray, df['cuisine'])\n",
    "# print(random_forest.score(ingredients_asArray, df.cuisine))\n",
    "# random_forest_predictions = random_forest.predict(ingredients_asArray_test)\n",
    "\n",
    "# .76559"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Multinomial Naive Bayes is a classification technique with discrete \n",
    "# features (ie. words counts for text classification). Given prior \n",
    "# probabilities of a given word(s) in a document, calculate the \n",
    "# posterior probability that a set of words will be in some class.\n",
    "\n",
    "# multi_naive_bayes = MultinomialNB()\n",
    "# multi_naive_bayes = multi_naive_bayes.fit(bag_of_words_asArray, df['cuisine'])\n",
    "# multi_naive_bayes_predictions = multi_naive_bayes.predict(ingredients_asArray_test)\n",
    "\n",
    "# .72084"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Support Vector Machines create a hyperplane (or decision boundary) that \n",
    "# maximizes the distance to the nearest points or margin. Correct \n",
    "# classification of a point is more important than maximizing the margin.\n",
    "\n",
    "# Kernal Trick turns a non-separable cluster of points into a high input/\n",
    "# high dimensional space.\n",
    "\n",
    "# Parameters: kernal-linear, rbf (default and non-linear); C-controls \n",
    "# tradeoff btwn decision boundary and correct point classification (the\n",
    "# more non-linear and wiggly boundary results in higher change of overfitting),\n",
    "# larger C more correct points; gamma-how non-linear the boundary is.\n",
    "\n",
    "# Use linear kernal when no. features is larger than no. obserations,\n",
    "# use gaussian kernal when no. observations is larger than no. features,\n",
    "# use linear kernal if no. observations is greater than 50k for speed.\n",
    "\n",
    "# supp_vec = SVC()\n",
    "# supp_vec = supp_vec.fit(bag_of_words_asArray, df['cuisine'])\n",
    "# supp_vec_predictions = supp_vec.predict(ingredients_asArray_test)\n",
    "\n",
    "# .57683"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stochastic Gradient Descent looks at the errors of each point and \n",
    "# determines which way they're pointing (slope tells you which way \n",
    "# to go) and then move that way until the errors stop getting smaller. \n",
    "\n",
    "stoch_grad = SGDClassifier()\n",
    "stoch_grad = stoch_grad.fit(bag_of_words_asArray, df['cuisine'])\n",
    "stoch_grad_predictions = stoch_grad.predict(ingredients_asArray_test)\n",
    "\n",
    "# .74356"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print results output to csv\n",
    "# model_predictions = random_forest_predictions\n",
    "# model_predictions = multi_naive_bayes_predictions\n",
    "# model_predictions = supp_vec_predictions\n",
    "model_predictions = stoch_grad_predictions \n",
    "d = {'id': df_test['id'], 'cuisine': model_predictions}\n",
    "output = pd.DataFrame(data = d)\n",
    "output.to_csv(\"/Users/dominicdebiaso/Desktop/kaggle_whats_cooking_model.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sources\n",
    "# http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "# https://www.kaggle.com/normallydistrbuted/whats-cooking/simple-bag-of-words-with-rf/code\n",
    "# https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-2-word-vectors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
